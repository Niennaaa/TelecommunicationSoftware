{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "REQUEST : \n",
      "{\n",
      "  \"args\": {}, \n",
      "  \"headers\": {\n",
      "    \"Accept\": \"*/*\", \n",
      "    \"Accept-Encoding\": \"gzip, deflate, br\", \n",
      "    \"Host\": \"httpbin.org\", \n",
      "    \"User-Agent\": \"python-requests/2.31.0\", \n",
      "    \"X-Amzn-Trace-Id\": \"Root=1-65a7b2bf-26d8457035e0f3753fa23f80\"\n",
      "  }, \n",
      "  \"origin\": \"85.254.221.245\", \n",
      "  \"url\": \"http://httpbin.org/get\"\n",
      "}\n",
      "\n",
      "200\n",
      "ascii\n",
      "\n",
      "\n",
      "\n",
      "GET : \n",
      "{\n",
      "  \"args\": {}, \n",
      "  \"headers\": {\n",
      "    \"Accept\": \"*/*\", \n",
      "    \"Accept-Encoding\": \"gzip, deflate, br\", \n",
      "    \"Host\": \"httpbin.org\", \n",
      "    \"User-Agent\": \"python-requests/2.31.0\", \n",
      "    \"X-Amzn-Trace-Id\": \"Root=1-65a7b2c0-635c5c5f71813c467bf73a62\"\n",
      "  }, \n",
      "  \"origin\": \"85.254.221.245\", \n",
      "  \"url\": \"http://httpbin.org/get\"\n",
      "}\n",
      "\n",
      "200\n",
      "ascii\n",
      "\n",
      "\n",
      "\n",
      "HEAD : \n",
      "\n",
      "200\n",
      "None\n",
      "\n",
      "\n",
      "\n",
      "POST : \n",
      "{\n",
      "  \"args\": {}, \n",
      "  \"data\": \"\", \n",
      "  \"files\": {}, \n",
      "  \"form\": {}, \n",
      "  \"headers\": {\n",
      "    \"Accept\": \"*/*\", \n",
      "    \"Accept-Encoding\": \"gzip, deflate, br\", \n",
      "    \"Content-Length\": \"0\", \n",
      "    \"Host\": \"httpbin.org\", \n",
      "    \"User-Agent\": \"python-requests/2.31.0\", \n",
      "    \"X-Amzn-Trace-Id\": \"Root=1-65a7b2c0-71303cbf6ddaccc03662c892\"\n",
      "  }, \n",
      "  \"json\": null, \n",
      "  \"origin\": \"85.254.221.245\", \n",
      "  \"url\": \"http://httpbin.org/post\"\n",
      "}\n",
      "\n",
      "200\n",
      "ascii\n",
      "\n",
      "\n",
      "\n",
      "PUT : \n",
      "{\n",
      "  \"args\": {}, \n",
      "  \"data\": \"\", \n",
      "  \"files\": {}, \n",
      "  \"form\": {}, \n",
      "  \"headers\": {\n",
      "    \"Accept\": \"*/*\", \n",
      "    \"Accept-Encoding\": \"gzip, deflate, br\", \n",
      "    \"Content-Length\": \"0\", \n",
      "    \"Host\": \"httpbin.org\", \n",
      "    \"User-Agent\": \"python-requests/2.31.0\", \n",
      "    \"X-Amzn-Trace-Id\": \"Root=1-65a7b2c0-04decb382eaac969034cf598\"\n",
      "  }, \n",
      "  \"json\": null, \n",
      "  \"origin\": \"85.254.221.245\", \n",
      "  \"url\": \"http://httpbin.org/put\"\n",
      "}\n",
      "\n",
      "200\n",
      "ascii\n",
      "\n",
      "\n",
      "\n",
      "PATCH : \n",
      "{\n",
      "  \"args\": {}, \n",
      "  \"data\": \"\", \n",
      "  \"files\": {}, \n",
      "  \"form\": {}, \n",
      "  \"headers\": {\n",
      "    \"Accept\": \"*/*\", \n",
      "    \"Accept-Encoding\": \"gzip, deflate, br\", \n",
      "    \"Content-Length\": \"0\", \n",
      "    \"Host\": \"httpbin.org\", \n",
      "    \"User-Agent\": \"python-requests/2.31.0\", \n",
      "    \"X-Amzn-Trace-Id\": \"Root=1-65a7b2c0-0f97d29c25ed5fc8000d6e28\"\n",
      "  }, \n",
      "  \"json\": null, \n",
      "  \"origin\": \"85.254.221.245\", \n",
      "  \"url\": \"http://httpbin.org/patch\"\n",
      "}\n",
      "\n",
      "200\n",
      "ascii\n",
      "\n",
      "\n",
      "\n",
      "DELETE : \n",
      "{\n",
      "  \"args\": {}, \n",
      "  \"data\": \"\", \n",
      "  \"files\": {}, \n",
      "  \"form\": {}, \n",
      "  \"headers\": {\n",
      "    \"Accept\": \"*/*\", \n",
      "    \"Accept-Encoding\": \"gzip, deflate, br\", \n",
      "    \"Content-Length\": \"0\", \n",
      "    \"Host\": \"httpbin.org\", \n",
      "    \"User-Agent\": \"python-requests/2.31.0\", \n",
      "    \"X-Amzn-Trace-Id\": \"Root=1-65a7b2c1-435216581805d3ec32235b5a\"\n",
      "  }, \n",
      "  \"json\": null, \n",
      "  \"origin\": \"85.254.221.245\", \n",
      "  \"url\": \"http://httpbin.org/delete\"\n",
      "}\n",
      "\n",
      "200\n",
      "ascii\n",
      "\n",
      "\n",
      "\n",
      "PARAMS : \n",
      "{\n",
      "  \"args\": {\n",
      "    \"key1\": \"value1\", \n",
      "    \"key2\": \"value2\"\n",
      "  }, \n",
      "  \"headers\": {\n",
      "    \"Accept\": \"*/*\", \n",
      "    \"Accept-Encoding\": \"gzip, deflate, br\", \n",
      "    \"Host\": \"httpbin.org\", \n",
      "    \"User-Agent\": \"python-requests/2.31.0\", \n",
      "    \"X-Amzn-Trace-Id\": \"Root=1-65a7b2c1-6a18bea64395b5be20591cc0\"\n",
      "  }, \n",
      "  \"origin\": \"85.254.221.245\", \n",
      "  \"url\": \"http://httpbin.org/get?key1=value1&key2=value2\"\n",
      "}\n",
      "\n",
      "200\n",
      "ascii\n",
      "\n",
      "\n",
      "\n",
      "DATA : \n",
      "{\n",
      "  \"args\": {}, \n",
      "  \"headers\": {\n",
      "    \"Accept\": \"*/*\", \n",
      "    \"Accept-Encoding\": \"gzip, deflate, br\", \n",
      "    \"Content-Length\": \"23\", \n",
      "    \"Content-Type\": \"application/x-www-form-urlencoded\", \n",
      "    \"Host\": \"httpbin.org\", \n",
      "    \"User-Agent\": \"python-requests/2.31.0\", \n",
      "    \"X-Amzn-Trace-Id\": \"Root=1-65a7b2c2-1d6d22e338d0d2fc33819d82\"\n",
      "  }, \n",
      "  \"origin\": \"85.254.221.245\", \n",
      "  \"url\": \"http://httpbin.org/get\"\n",
      "}\n",
      "\n",
      "200\n",
      "ascii\n",
      "\n",
      "\n",
      "\n",
      "JSON : \n",
      "{\n",
      "  \"args\": {}, \n",
      "  \"headers\": {\n",
      "    \"Accept\": \"*/*\", \n",
      "    \"Accept-Encoding\": \"gzip, deflate, br\", \n",
      "    \"Content-Length\": \"9\", \n",
      "    \"Content-Type\": \"application/json\", \n",
      "    \"Host\": \"httpbin.org\", \n",
      "    \"User-Agent\": \"python-requests/2.31.0\", \n",
      "    \"X-Amzn-Trace-Id\": \"Root=1-65a7b2c2-19434aa4427922147ad84019\"\n",
      "  }, \n",
      "  \"origin\": \"85.254.221.245\", \n",
      "  \"url\": \"http://httpbin.org/get\"\n",
      "}\n",
      "\n",
      "200\n",
      "ascii\n",
      "\n",
      "\n",
      "\n",
      "HEADERS : \n",
      "{\n",
      "  \"args\": {}, \n",
      "  \"headers\": {\n",
      "    \"Accept\": \"*/*\", \n",
      "    \"Accept-Encoding\": \"gzip, deflate, br\", \n",
      "    \"Host\": \"httpbin.org\", \n",
      "    \"Key1\": \"value1\", \n",
      "    \"Key2\": \"value2\", \n",
      "    \"User-Agent\": \"python-requests/2.31.0\", \n",
      "    \"X-Amzn-Trace-Id\": \"Root=1-65a7b2c2-1147fd977327c3f2398f43f7\"\n",
      "  }, \n",
      "  \"origin\": \"85.254.221.245\", \n",
      "  \"url\": \"http://httpbin.org/get\"\n",
      "}\n",
      "\n",
      "200\n",
      "ascii\n",
      "\n",
      "\n",
      "\n",
      "COOKIES : \n",
      "{\n",
      "  \"args\": {}, \n",
      "  \"headers\": {\n",
      "    \"Accept\": \"*/*\", \n",
      "    \"Accept-Encoding\": \"gzip, deflate, br\", \n",
      "    \"Cookie\": \"key1=value1; key2=value2\", \n",
      "    \"Host\": \"httpbin.org\", \n",
      "    \"User-Agent\": \"python-requests/2.31.0\", \n",
      "    \"X-Amzn-Trace-Id\": \"Root=1-65a7b2c2-619f18db286258f97e5cd17c\"\n",
      "  }, \n",
      "  \"origin\": \"85.254.221.245\", \n",
      "  \"url\": \"http://httpbin.org/get\"\n",
      "}\n",
      "\n",
      "200\n",
      "ascii\n",
      "\n",
      "\n",
      "\n",
      "AUTH : \n",
      "{\n",
      "  \"args\": {}, \n",
      "  \"headers\": {\n",
      "    \"Accept\": \"*/*\", \n",
      "    \"Accept-Encoding\": \"gzip, deflate, br\", \n",
      "    \"Authorization\": \"Basic dXNlcjpwYXNz\", \n",
      "    \"Host\": \"httpbin.org\", \n",
      "    \"User-Agent\": \"python-requests/2.31.0\", \n",
      "    \"X-Amzn-Trace-Id\": \"Root=1-65a7b2c3-27908f461e708adc7120354c\"\n",
      "  }, \n",
      "  \"origin\": \"85.254.221.245\", \n",
      "  \"url\": \"http://httpbin.org/get\"\n",
      "}\n",
      "\n",
      "200\n",
      "ascii\n",
      "\n",
      "\n",
      "\n",
      "FILES : \n",
      "{\n",
      "  \"args\": {}, \n",
      "  \"headers\": {\n",
      "    \"Accept\": \"*/*\", \n",
      "    \"Accept-Encoding\": \"gzip, deflate, br\", \n",
      "    \"Content-Length\": \"254\", \n",
      "    \"Content-Type\": \"multipart/form-data; boundary=73e3b624c4822ba47fadb8cd6ffa8a55\", \n",
      "    \"Host\": \"httpbin.org\", \n",
      "    \"User-Agent\": \"python-requests/2.31.0\", \n",
      "    \"X-Amzn-Trace-Id\": \"Root=1-65a7b2c3-4f491ab302d79f146745264a\"\n",
      "  }, \n",
      "  \"origin\": \"85.254.221.245\", \n",
      "  \"url\": \"http://httpbin.org/get\"\n",
      "}\n",
      "\n",
      "200\n",
      "ascii\n",
      "\n",
      "\n",
      "\n",
      "TIMEOUT : \n",
      "{\n",
      "  \"args\": {}, \n",
      "  \"headers\": {\n",
      "    \"Accept\": \"*/*\", \n",
      "    \"Accept-Encoding\": \"gzip, deflate, br\", \n",
      "    \"Host\": \"httpbin.org\", \n",
      "    \"User-Agent\": \"python-requests/2.31.0\", \n",
      "    \"X-Amzn-Trace-Id\": \"Root=1-65a7b2c3-059f9b027ff33a4b17eb1b82\"\n",
      "  }, \n",
      "  \"origin\": \"85.254.221.245\", \n",
      "  \"url\": \"http://httpbin.org/get\"\n",
      "}\n",
      "\n",
      "200\n",
      "ascii\n",
      "\n",
      "\n",
      "\n",
      "PROXIES : \n",
      "{\n",
      "  \"args\": {}, \n",
      "  \"headers\": {\n",
      "    \"Accept\": \"*/*\", \n",
      "    \"Accept-Encoding\": \"gzip, deflate, br\", \n",
      "    \"Host\": \"httpbin.org\", \n",
      "    \"User-Agent\": \"python-requests/2.31.0\", \n",
      "    \"X-Amzn-Trace-Id\": \"Root=1-65a7b2c3-796c0e0a4927d8cb41a0448a\"\n",
      "  }, \n",
      "  \"origin\": \"85.254.221.245\", \n",
      "  \"url\": \"http://httpbin.org/get\"\n",
      "}\n",
      "\n",
      "200\n",
      "ascii\n",
      "\n",
      "\n",
      "\n",
      "ALLOW_REDIRECTS : \n",
      "{\n",
      "  \"args\": {}, \n",
      "  \"headers\": {\n",
      "    \"Accept\": \"*/*\", \n",
      "    \"Accept-Encoding\": \"gzip, deflate, br\", \n",
      "    \"Host\": \"httpbin.org\", \n",
      "    \"User-Agent\": \"python-requests/2.31.0\", \n",
      "    \"X-Amzn-Trace-Id\": \"Root=1-65a7b2c4-5a67cea645ca368b323ab8f9\"\n",
      "  }, \n",
      "  \"origin\": \"85.254.221.245\", \n",
      "  \"url\": \"http://httpbin.org/get\"\n",
      "}\n",
      "\n",
      "200\n",
      "ascii\n",
      "\n",
      "\n",
      "\n",
      "STREAM : \n",
      "{\n",
      "  \"args\": {}, \n",
      "  \"headers\": {\n",
      "    \"Accept\": \"*/*\", \n",
      "    \"Accept-Encoding\": \"gzip, deflate, br\", \n",
      "    \"Host\": \"httpbin.org\", \n",
      "    \"User-Agent\": \"python-requests/2.31.0\", \n",
      "    \"X-Amzn-Trace-Id\": \"Root=1-65a7b2c4-2bc46d3632957bfd753a0f33\"\n",
      "  }, \n",
      "  \"origin\": \"85.254.221.245\", \n",
      "  \"url\": \"http://httpbin.org/get\"\n",
      "}\n",
      "\n",
      "200\n",
      "ascii\n",
      "\n",
      "\n",
      "\n",
      "VERIFY : \n",
      "{\n",
      "  \"args\": {}, \n",
      "  \"headers\": {\n",
      "    \"Accept\": \"*/*\", \n",
      "    \"Accept-Encoding\": \"gzip, deflate, br\", \n",
      "    \"Host\": \"httpbin.org\", \n",
      "    \"User-Agent\": \"python-requests/2.31.0\", \n",
      "    \"X-Amzn-Trace-Id\": \"Root=1-65a7b2c5-6e699a1829675a4d60c46f85\"\n",
      "  }, \n",
      "  \"origin\": \"85.254.221.245\", \n",
      "  \"url\": \"http://httpbin.org/get\"\n",
      "}\n",
      "\n",
      "200\n",
      "ascii\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Exemple 1 \n",
    "#Test requests Python library, including seven types of methods \n",
    "#and 13 parameters to control access\n",
    "\n",
    "\"\"\"\n",
    "From the class : \n",
    "7 METHODS \n",
    "requests.request() constructs a request that supports the basic methods of the following methods\n",
    "requests.get() The main method for obtaining HTML pages corresponding to HTTP GET\n",
    "requests.head() The method to obtain the header information of HTML pages, corresponding to the HEAD of HTTP\n",
    "requests.post() Method for submitting POST requests to HTML pages, corresponding to HTTP POST\n",
    "requests.put() The method of submitting a PUT request to an HTML page, corresponding to HTTP PUT\n",
    "requests.patch() Submit a partial modification request to an HTML page, corresponding to HTTP PATCH\n",
    "requests.delete() Submit a delete request to the HTML page, corresponding to HTTP DELETE\n",
    "\n",
    "13 PARAMETERS\n",
    "params: dictionary or byte sequence, added to the url as a parameter\n",
    "data: dictionary, byte sequence or file object, as the content of the Request\n",
    "JSON : data in JSON format, as the content of Request\n",
    "headers: dictionary, HTTP custom headers\n",
    "cookies: dictionary or CookieJar, cookies in Request\n",
    "auth: tuple, support HTTP authentication function\n",
    "files: dictionary type, transfer files\n",
    "timeout: Set the timeout time in seconds\n",
    "proxies: dictionary type, set the access proxy server, you can add login authentication\n",
    "allow_redirects: True/False, the default is True, redirect switch\n",
    "stream: True/False, the default is True, get the content immediately download switch\n",
    "verify: True/False, the default is True, verify the SSL certificate switch\n",
    "cert: local SSL certificate path\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#The 7 methods :\n",
    "import requests \n",
    "r1 = requests.request('GET',\"http://httpbin.org/get\")\n",
    "r2 = requests.get(\"http://httpbin.org/get\")\n",
    "r3 = requests.head(\"http://httpbin.org/get\")\n",
    "r4 = requests.post(\"http://httpbin.org/post\")\n",
    "r5 = requests.put(\"http://httpbin.org/put\")\n",
    "r6 = requests.patch(\"http://httpbin.org/patch\")\n",
    "r7 = requests.delete(\"http://httpbin.org/delete\")\n",
    "r = [r1, r2, r3, r4, r5, r6, r7]\n",
    "equi = [\"REQUEST\", \"GET\", \"HEAD\", \"POST\", \"PUT\", \"PATCH\", \"DELETE\"]\n",
    "n = 0\n",
    "for rr in r: \n",
    "    try :\n",
    "        rr.raise_for_status()\n",
    "        rr.encoding = rr.apparent_encoding\n",
    "        print(\"\\n\" + equi[n]+ \" : \")\n",
    "        print(rr.text[0:600])\n",
    "        print(rr.status_code)\n",
    "        print(rr.encoding)\n",
    "        print(\"\\n\")\n",
    "        n=n+1\n",
    "    except : \n",
    "        print(\"Not this one :\" + str(rr))\n",
    "        n=n+1\n",
    "\n",
    "url = \"http://httpbin.org/get\"\n",
    "kv = {'key1':'value1', 'key2':'value2'}\n",
    "body = \"content\"\n",
    "\n",
    "#The 13 parameters : \n",
    "r1 = requests.get(url, params = kv)\n",
    "r2 = requests.get(url, data = kv)\n",
    "r3 = requests.get(url, json = body)\n",
    "r4 = requests.get(url, headers = kv)\n",
    "r5 = requests.get(url, cookies = kv)\n",
    "r6 = requests.get(url, auth = ('user', 'pass'))\n",
    "r7 = requests.get(url, files = kv)\n",
    "r8 = requests.get(url, timeout = 100)\n",
    "r9 = requests.get(url, proxies = kv)\n",
    "r10 = requests.get(url, allow_redirects = False)\n",
    "r11 = requests.get(url, stream = False)\n",
    "r12 = requests.get(url, verify = False)\n",
    "#r13 = requests.get(url, cert = ('client.cert', 'client.key'))\n",
    "r = [r1, r2, r3, r4, r5, r6, r7, r8, r9, r10, r11, r12]\n",
    "equi = [\"PARAMS\", \"DATA\", \"JSON\", \"HEADERS\", \"COOKIES\", \"AUTH\", \\\n",
    "        \"FILES\", \"TIMEOUT\", \"PROXIES\", \"ALLOW_REDIRECTS\", \"STREAM\", \"VERIFY\", \"CERT\"]\n",
    "n = 0\n",
    "for rr in r: \n",
    "    try :\n",
    "        rr.raise_for_status()\n",
    "        rr.encoding = rr.apparent_encoding\n",
    "        print(\"\\n\" + equi[n]+ \" : \")\n",
    "        print(rr.text[0:600])\n",
    "        print(rr.status_code)\n",
    "        print(rr.encoding)\n",
    "        print(\"\\n\")\n",
    "        n=n+1\n",
    "    except : \n",
    "        print(\"Not this one :\" + str(rr))\n",
    "        n=n+1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.bing.com/search?q=meme\n",
      "81755\n",
      "200\n",
      "utf-8\n"
     ]
    }
   ],
   "source": [
    "#Exemple 2 \n",
    "#Search engine keyword submission interface with requests python library.\n",
    "\n",
    "import requests \n",
    "keyword = \"meme\"\n",
    "try : \n",
    "    kv = {'q':keyword} #I followed the same logic as the one we've seen in the lecture\n",
    "    r = requests.get(\"http://www.bing.com/search\", params = kv)\n",
    "    print(r.request.url)\n",
    "    r.raise_for_status()\n",
    "    print(len(r.text))\n",
    "except :\n",
    "    print(\"Abnormal detected\")\n",
    "    \n",
    "print(r.status_code)\n",
    "print(r.encoding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exist\n"
     ]
    }
   ],
   "source": [
    "#Exemple 3 \n",
    "#  Image crawling. \n",
    "import requests \n",
    "import os\n",
    "url = \"https://i.imgflip.com/2ghngj.jpg\"\n",
    "root = \"C:/Users/Jehanne/Downloads/\"\n",
    "path = root+url.split(\"/\")[-1]\n",
    "\n",
    "#I followed the same logic as seen in class\n",
    "if not os.path.exists(root):\n",
    "    os.nkdir(root)\n",
    "if not os.path.exists(path):#Get image\n",
    "    r = requests.get(url)\n",
    "    with open(path, \"wb\") as f : \n",
    "        f.write(r.content) #Save it \n",
    "        f.close()\n",
    "        print(\"File saved\")\n",
    "else : \n",
    "    print(\"File already exist\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Rank                                   University  Score\n",
      "0     1                           Harvard University  100.0\n",
      "1     2                          Stanford University   74.8\n",
      "2     3  Massachusetts Institute of Technology (MIT)   69.1\n",
      "3     4                      University of Cambridge   67.9\n",
      "4     5           University of California, Berkeley   63.4\n",
      "5     6                         Princeton University   60.1\n",
      "6     7                         University of Oxford   59.5\n",
      "7     8                          Columbia University   55.3\n",
      "8     9           California Institute of Technology   54.5\n",
      "9    10                        University of Chicago   53.8\n",
      "10   11                              Yale University   52.2\n",
      "11   12                           Cornell University   50.5\n",
      "12   13        University of California, Los Angeles   48.0\n",
      "13   14                   University of Pennsylvania   47.7\n",
      "14   15                      Paris-Saclay University   47.0\n",
      "15   16                     Johns Hopkins University   46.8\n",
      "16   17                    University College London   45.9\n",
      "17   18                     University of Washington   45.4\n",
      "18   19          University of California, San Diego   44.8\n",
      "19   20                                   ETH Zurich   44.1\n",
      "20   21      University of California, San Francisco   44.0\n",
      "21   22                          Tsinghua University   40.3\n",
      "22   23                      Imperial College London   39.9\n",
      "23   24                        University of Toronto   39.7\n",
      "24   25           Washington University in St. Louis   39.0\n",
      "25   26             University of Michigan-Ann Arbor   37.8\n",
      "26   27                      The University of Tokyo   37.7\n",
      "27   28                          New York University   37.3\n",
      "28   29                            Peking University   36.7\n",
      "29   30                      Northwestern University   35.8\n"
     ]
    }
   ],
   "source": [
    "#Exemple 4 \n",
    "#University ranking print\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#Input: University ranking URL link\n",
    "Link: https://www.shanghairanking.com/rankings/arwu/2023\n",
    "\n",
    "#Output: Screen output of university ranking information (rank, #university name, total score)\n",
    "\n",
    "#Technical route: requests‐bs4 or requests‐lxml\n",
    "\n",
    "#Step 1: Obtain university ranking webpage content from the web\n",
    "#Step 2: Extract the information in the web page content into a suitable data structure\n",
    "#Step 3: Use data structures to display and output results\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import bs4\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "#We will output the reult as a pandas dataframe\n",
    "header = [\"Rank\", \"University\", \"Score\"]\n",
    "result = pd.DataFrame(columns = header)\n",
    "r = requests.get(\"https://www.shanghairanking.com/rankings/arwu/2023\")\n",
    "demo = r.text\n",
    "soup = BeautifulSoup(demo, 'html.parser')\n",
    "\n",
    "for tr in soup.find('tbody').children:\n",
    "    if isinstance(tr, bs4.element.Tag):\n",
    "        tds = tr('td')\n",
    "        #First I get the data :\n",
    "        rank =tds[0].find_all(string = re.compile(''))[-1].replace(\"\\n\",\"\")\n",
    "        university = tds[1].find_all(string = re.compile(''))[-1]\n",
    "        score = tds[4].find_all(string = re.compile(''))[-1].replace(\"\\n\",\"\")\n",
    "        #Then I add it to my result\n",
    "        result.loc[len(result)] = [rank, university, score]\n",
    "print(result)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.aliexpress.com/w/wholesale-plushie.html?spm=a2g0o.productlist.search.0\n",
      "                                                Name   Price Rating\n",
      "0  Bat Plush Toy manta Kawaii Animal Creative Plu...   €0.63    93%\n",
      "1  18cm FNAF Stuffed Plush Toys Freddy Fazbear Be...   €1.27    92%\n",
      "2  Original Sanrio Plushies Hello Kitty Cinnamonr...   €3.08    75%\n",
      "3  Skzoo Plush Toys 20cm Stray Kids Plush Wolf Ch...   €0.46    95%\n",
      "4  Gaint White Goose Plush Toy Super Soft Goose S...   €20.7   None\n",
      "5  40-50cm Sanrio Pompompurin Stuffed Plush Toys ...  €23.54    68%\n",
      "6  Genshin Game Anime Figure Doll Fluffy Cat Plus...   €1.31    87%\n",
      "7  20cm We Bare Bears Cartoon Plush Toys Standing...    €0.7    95%\n",
      "8  Cuddly Little Cat Plush Pendant Toy Fluffy Kit...   €0.46    94%\n",
      "9  Angry Blob Seal Pillow Popular Soft Chubby 3D ...    €3.2    59%\n"
     ]
    }
   ],
   "source": [
    "#Example 5:  \n",
    "#Crawling of goods web pages and printing relevant numbers, goods names, and prices with requests from the Python library.\n",
    "\n",
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "import bs4\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "#I created this function to work with aliexpress.com\n",
    "#It was a challenge because the place of the price changes based on the reductions\n",
    "keyword = \"plushie\"\n",
    "url = \"https://www.aliexpress.com/w/wholesale-\"+keyword+\".html?spm=a2g0o.productlist.search.0\"\n",
    "\n",
    "\n",
    "try : \n",
    "    r = requests.get(url)\n",
    "    print(r.request.url)\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    prettified= soup.prettify()\n",
    "    \n",
    "except :\n",
    "    print(\"Abnormal detected\")\n",
    "    \n",
    "soup0 = soup.find_all(class_=\"multi--content--11nFIBL\")\n",
    "\n",
    "alllist = []\n",
    "index = 0\n",
    "name = []\n",
    "prices = []\n",
    "rating = []\n",
    "headers = [\"Name\", \"Price\", \"Rating\"]\n",
    "results = pd.DataFrame(columns =headers)\n",
    "for div in soup0:\n",
    "    #I get all the data i need :\n",
    "    alllist.append(div.get_text(separator=';', strip=True).split(\";\"))\n",
    "    name.append(alllist[index][0])\n",
    "    \n",
    "    price = alllist[index][2]+alllist[index][3]+alllist[index][4]+alllist[index][5]\n",
    "    prices.append(price)\n",
    "    \n",
    "    if len(alllist[index][-3])>3: \n",
    "        rating.append(None)\n",
    "    else :\n",
    "        rating.append(alllist[index][-3])\n",
    "    \n",
    "    index+=1\n",
    "    \n",
    "    \n",
    "    #And add it to my result\n",
    "\n",
    "for i in range(len(name)):\n",
    "    results.loc[i] = [name[i], prices[i], rating[i]]\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 6:  \n",
    "\n",
    "#See in project report, this was done in VScode"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
